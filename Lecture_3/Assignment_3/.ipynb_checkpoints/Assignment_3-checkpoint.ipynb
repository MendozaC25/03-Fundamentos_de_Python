{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyreadstat\n",
      "  Downloading pyreadstat-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ftq\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
      "Downloading pyreadstat-1.2.7-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 12.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyreadstat\n",
      "Successfully installed pyreadstat-1.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID1             HHID              CASEID  V001  V002  V003  V004  \\\n",
      "0  2019.0        000100201        000100201  2   1.0   2.0   2.0   1.0   \n",
      "1  2019.0        000100201        000100201  3   1.0   2.0   3.0   1.0   \n",
      "2  2019.0        000102801        000102801  2   1.0  28.0   2.0   1.0   \n",
      "3  2019.0        000102801        000102801  6   1.0  28.0   6.0   1.0   \n",
      "4  2019.0        000104801        000104801  2   1.0  48.0   2.0   1.0   \n",
      "\n",
      "     V007    V008  V009  ...  QD333_4  QD333_5  QD333_6  UBIGEO  V022  \\\n",
      "0  2019.0  1434.0   4.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "1  2019.0  1434.0   1.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "2  2019.0  1434.0   6.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "3  2019.0  1434.0   3.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "4  2019.0  1434.0   5.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "\n",
      "       V005  V190      V191  mujeres12a49  NCONGLOME  \n",
      "0  154803.0   4.0  1.234450           2.0     7065.0  \n",
      "1  154803.0   4.0  1.234450           0.0     7065.0  \n",
      "2  154803.0   4.0  1.295611           2.0     7065.0  \n",
      "3  154803.0   4.0  1.295611           2.0     7065.0  \n",
      "4  154803.0   2.0 -0.256431           2.0     7065.0  \n",
      "\n",
      "[5 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ruta a los archivos\n",
    "path = \"../../_data/endes/2019/\"\n",
    "\n",
    "# Leer los archivos y extraer datos y etiquetas\n",
    "rec_1, meta1 = pyreadstat.read_sav(path + \"REC0111.sav\")\n",
    "rec_2, meta2 = pyreadstat.read_sav(path + \"RE223132.sav\")\n",
    "rec_3, meta3 = pyreadstat.read_sav(path + \"RE516171.sav\")\n",
    "\n",
    "var_labels1 = meta1.column_names_to_labels\n",
    "value_labels1 = meta1.value_labels\n",
    "var_labels2 = meta2.column_names_to_labels\n",
    "value_labels2 = meta2.value_labels\n",
    "var_labels3 = meta3.column_names_to_labels\n",
    "value_labels3 = meta3.value_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set. Check if all the columns are in the dataset. Make a code that check the columns that are not included. Please, reporte them.\n",
    "\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas a seleccionar\n",
    "columns_rec1 = [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"]\n",
    "columns_rec2 = [\"CASEID\", \"V201\", \"V218\", \"V301\", \"V302\", \"V323\", \"V323A\", \"V325A\", \"V326\", \"V327\", \"V337\", \"V359\", \"V360\", \"V361\", \"V362\", \"V363\", \"V364\", \"V367\", \"V372\", \"V372A\", \"V375A\", \"V376\", \"V376A\", \"V379\", \"V380\"]\n",
    "columns_rec3 = [\"CASEID\", \"V501\", \"V502\", \"V503\", \"V504\", \"V505\", \"V506\", \"V507\", \"V508\", \"V509\", \"V510\", \"V511\", \"V512\", \"V513\", \"V525\", \"V613\", \"V714\", \"V715\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas presentes en rec_1: ['ID1', 'HHID', 'CASEID', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V013', 'V014', 'V015', 'V017', 'V018', 'V019', 'V019A', 'V020', 'V021', 'V023', 'V024', 'V025', 'V026', 'V027', 'V028', 'V029', 'V030', 'V031', 'V032', 'V033', 'V034', 'V040', 'V042', 'V043', 'V044', 'V000', 'Q105DD', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V113', 'V115', 'V116', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V128', 'V129', 'V130', 'V131', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V149', 'V150', 'V151', 'V152', 'V153', 'AWFACTT', 'AWFACTU', 'AWFACTR', 'AWFACTE', 'AWFACTW', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V166', 'V167', 'V168', 'ML101', 'QD333_1', 'QD333_2', 'QD333_3', 'QD333_4', 'QD333_5', 'QD333_6', 'UBIGEO', 'V022', 'V005', 'V190', 'V191', 'mujeres12a49', 'NCONGLOME']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las columnas presentes en rec_1 para verificar\n",
    "print(\"Columnas presentes en rec_1:\", rec_1.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las siguientes columnas no están en rec1: []\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar columnas y reportar las que no están presentes para rec1\n",
    "missing_columns_rec1 = [col for col in columns_rec1 if col not in rec_1.columns]\n",
    "print(f\"Las siguientes columnas no están en rec1: {missing_columns_rec1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_columns_rec1 = [col for col in columns_rec1 if col in rec_1.columns]\n",
    "rec1_1 = rec_1[present_columns_rec1]\n",
    "new_var_labels1 = {col: var_labels1[col] for col in present_columns_rec1}\n",
    "new_value_labels1 = {col: value_labels1[col] for col in present_columns_rec1 if col in value_labels1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las siguientes columnas no están en rec2: []\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar columnas y reportar las que no están presentes para rec2\n",
    "missing_columns_rec2 = [col for col in columns_rec2 if col not in rec_2.columns]\n",
    "print(f\"Las siguientes columnas no están en rec2: {missing_columns_rec2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_columns_rec2 = [col for col in columns_rec2 if col in rec_2.columns]\n",
    "rec2_1 = rec_2[present_columns_rec2]\n",
    "new_var_labels2 = {col: var_labels2[col] for col in present_columns_rec2}\n",
    "new_value_labels2 = {col: value_labels2[col] for col in present_columns_rec2 if col in value_labels2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las siguientes columnas no están en rec3: []\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar columnas y reportar las que no están presentes para rec3\n",
    "missing_columns_rec3 = [col for col in columns_rec3 if col not in rec_3.columns]\n",
    "print(f\"Las siguientes columnas no están en rec3: {missing_columns_rec3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_columns_rec3 = [col for col in columns_rec3 if col in rec_3.columns]\n",
    "rec3_1 = rec_3[present_columns_rec3]\n",
    "new_var_labels3 = {col: var_labels3[col] for col in present_columns_rec3}\n",
    "new_value_labels3 = {col: value_labels3[col] for col in present_columns_rec3 if col in value_labels3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CASEID': 'Identificación Cuestionario Individual', 'V000': 'Código y fase del país', 'V001': 'Conglomerado', 'V002': 'Número de vivienda', 'V003': 'Número de línea de entrevistada', 'V004': 'Unidad de área final', 'V007': 'Año de la entrevista', 'V008': 'Fecha de la entrevista, Codificación centenaria de meses (CMC)', 'V009': 'Mes de nacimiento de la entrevistada', 'V010': 'Año de nacimiento de la entrevistada', 'V011': 'Fecha de nacimiento, Codificación centenaria de meses (CMC)', 'V012': 'Edad actual - entrevistada', 'V024': 'Región', 'V102': 'Tipo de lugar de residencia', 'V120': 'En su hogar tiene: radio', 'V121': 'En su hogar tiene: televisión', 'V122': 'En su hogar tiene: refrigerador', 'V123': 'En su hogar tiene: bicicleta', 'V124': 'En su hogar tiene: motocicleta/motocar', 'V125': 'En su hogar tiene: coche/camión', 'V127': 'Material predominante del piso de la vivienda', 'V133': 'Educación en años simples'}\n",
      "{}\n",
      "{'CASEID': 'Identificación Cuestionario Individual', 'V201': 'Total de niños nacidos', 'V218': 'Número de niños vivos', 'V301': 'Conocimiento de cualquier método', 'V302': 'Alguna vez usó cualquier método', 'V323': 'Marca de la píldora usada', 'V323A': 'Marca del preservativo utilizado', 'V325A': 'Costo del método actual', 'V326': 'Fuente para obtener el actual método anticonceptivo', 'V327': 'Fuente para obtener el actual método anticonceptivo (Grupos)', 'V337': 'Meses de uso del método actual', 'V359': 'Última discontinuidad del método los últimos 5 años', 'V360': 'Motivo de la última discontinuidad', 'V361': 'Patrón de uso', 'V362': 'Intención de uso', 'V363': 'Método futuro preferido', 'V364': 'Uso e intención de anticonceptivos', 'V367': 'Quería quedar embarazada:', 'V372': 'Se muestra el paquete de pastillas', 'V372A': 'Se muestra el paquete de Condónes', 'V375A': 'La razón principal para no utilizar un método', 'V376': 'La razón principal por la que no piensa usar ningún método en el futuro', 'V376A': 'Alguna vez usaría algún método', 'V379': 'Fuente conocida por cualquier método', 'V380': 'Fuente conocida por cualquier método (Grupos)'}\n",
      "{}\n",
      "{'CASEID': 'Identificación Cuestionario Individual', 'V501': 'Estado civil actual', 'V502': 'Actualmente, antes o nunca sacada', 'V503': 'Usted ha estado casada o conviviendo solo una vez, más de una vez', 'V504': 'Su esposo/compañer vive en el hogar o vive en otro lugar', 'V505': 'Número de otras esposas', 'V506': 'Número de rango de la esposa', 'V507': 'Mes - Primer matrimonio', 'V508': 'Año - Primer matrimonio', 'V509': 'Fecha del primer matrimonio (CMC)', 'V510': 'Integridad de la información para la fecha de inicio del primer matrimonio o unión', 'V511': 'Edad al primer matrimonio', 'V512': 'Años desde el primer matrimonio', 'V513': 'Duración del matrimonio (agrupado)', 'V525': 'Edad en la primera relación sexual', 'V613': 'Número ideal de niños', 'V714': 'Actualmente se encuentra trabajando', 'V715': 'Educación en años individuales del esposo/compañero'}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los resultados\n",
    "print(new_var_labels1)\n",
    "print(new_value_labels1)\n",
    "\n",
    "print(new_var_labels2)\n",
    "print(new_value_labels2)\n",
    "\n",
    "print(new_var_labels3)\n",
    "print(new_value_labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar la columna 'year' con el valor 2019\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Crear un diccionario con la nueva entrada\n",
    "nueva_entrada = {'year': \"Year of the survey\"}\n",
    "\n",
    "# Actualizar el diccionario new_var_labels1\n",
    "new_var_labels1.update(nueva_entrada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
