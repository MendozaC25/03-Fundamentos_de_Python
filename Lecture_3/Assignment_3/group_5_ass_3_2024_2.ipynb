{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For this task, we met as a team 3 times during this week. All team members contributed to the assignment, as the work was done via the zoom platform, and for this reason, only the record of the report mantainerÂ exists.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\leidy\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\leidy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAV files saved in a dictionary named file_path \n",
    "file_paths = {'REC0111.sav' : '../../_data/endes/2019/REC0111.sav',\n",
    "             'RE223132.sav' : '../../_data/endes/2019/RE223132.sav',\n",
    "             'RE516171.sav' : '../../_data/endes/2019/RE516171.sav'}\n",
    "\n",
    "# Dictionaries are established to store base information, variables and values\n",
    "dataframes = {}\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "# For each file_path created, a loop is performed to read and store each of metadata, variables and values\n",
    "for file_name, file_path in file_paths.items():\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "    dataframes[file_name] = df\n",
    "    var_labels[file_name] = meta.column_labels\n",
    "    value_labels[file_name] = meta.variable_value_labels\n",
    "\n",
    "# Data are extracted from each of the three dictionaries created in order to assign these information to the indicated variables\n",
    "rec_1, rec_2, rec_3 = [dataframes[file] for file in file_paths]\n",
    "var_labels1, var_labels2, var_labels3 = [var_labels[file] for file in file_paths]\n",
    "value_labels1, value_labels2, value_labels3 = [value_labels[file] for file in file_paths]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set. Check if all the columns are in the dataset. Make a code that check the columns that are not included. Please, reporte them.\n",
    "\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists are used to store the variables to be needed\n",
    "columns_rec1 = [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"]\n",
    "columns_rec2 = [\"CASEID\", \"V201\", \"V218\", \"V301\", \"V302\", \"V323\", \"V323A\", \"V325A\", \"V326\", \"V327\", \"V337\", \"V359\", \"V360\", \"V361\", \"V362\", \"V363\", \"V364\", \"V367\", \"V372\", \"V372A\", \"V375A\", \"V376\", \"V376A\", \"V379\", \"V380\"]\n",
    "columns_rec3 = [\"CASEID\", \"V501\", \"V502\", \"V503\", \"V504\", \"V505\", \"V506\", \"V507\", \"V508\", \"V509\", \"V510\", \"V511\", \"V512\", \"V513\", \"V525\", \"V613\", \"V714\", \"V715\"]\n",
    "\n",
    "# Based on the list created, only the variables that match are selected and stored in rec*_1\n",
    "rec1_1 = rec_1.loc[:, columns_rec1]\n",
    "rec2_1 = rec_2.loc[:, columns_rec2]\n",
    "rec3_1 = rec_3.loc[:, columns_rec3]\n",
    "\n",
    "#Create two dictionary for every value and variable of dataframes \n",
    "new_var_labels1 = {key: var_labels1[key] for key in columns_rec1 if key in var_labels1}\n",
    "new_var_labels2 = {key: var_labels2[key] for key in columns_rec2 if key in var_labels2}\n",
    "new_var_labels3 = {key: var_labels3[key] for key in columns_rec3 if key in var_labels3}\n",
    "\n",
    "new_value_labels1 = update_value_labels(value_labels1, columns_rec1)\n",
    "new_value_labels2 = update_value_labels(value_labels2, columns_rec2)\n",
    "new_value_labels3 = update_value_labels(value_labels3, columns_rec3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The new column 'year' is created for 2019\n",
    "\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# The append function is used too add the newly created variable as 'Year of the survey' to the list of labels\n",
    "\n",
    "var_labels1.append('Year of the survey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The merge funtion is used to join the datafreames using CASEID as the matching variable. \n",
    "endes_2019 = rec1_1.merge(rec2_1, on='CASEID', how='inner').merge(rec3_1, on='CASEID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leidy\\AppData\\Local\\Temp\\ipykernel_22932\\3695174510.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  endes_2019.var_labels = var_labels\n",
      "C:\\Users\\leidy\\AppData\\Local\\Temp\\ipykernel_22932\\3695174510.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  endes_2019.value_labels = value_labels\n"
     ]
    }
   ],
   "source": [
    "# New dictionary is created to link all var labels together \n",
    "var_labels = {}\n",
    "var_labels.update(new_var_labels1)  \n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "# New dictionary is created to link all value labels together \n",
    "value_labels = {} \n",
    "value_labels.update(new_value_labels1) \n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# Adding labels joined to the database endes_2019\n",
    "endes_2019.var_labels = var_labels\n",
    "endes_2019.value_labels = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: savReaderWriter in c:\\users\\leidy\\anaconda3\\lib\\site-packages (3.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install savReaderWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list with years\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "\n",
    "# Nempty list\n",
    "all_data = {}\n",
    "\n",
    "# loop for read data and meta of each file, and then saved\n",
    "for year in years:\n",
    "    data_path = f\"../../_data/endes/{year}/\"\n",
    "\n",
    "    rec_1, meta_1 = pyreadstat.read_sav(os.path.join(data_path, 'REC0111.sav'))\n",
    "    rec_2, meta_2 = pyreadstat.read_sav(os.path.join(data_path, 'RE223132.sav'))\n",
    "    rec_3, meta_3 = pyreadstat.read_sav(os.path.join(data_path, 'RE516171.sav'))\n",
    "   \n",
    "    cols1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "    rec1_1 = rec_1.loc[:, cols1]\n",
    "    \n",
    "    cols2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "    rec2_1 = rec_2.loc[:, cols2]\n",
    "\n",
    "    cols3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "    rec3_1 = rec_3.loc[:, cols3]\n",
    "\n",
    "# Adding a column named year    \n",
    "    rec1_1.loc[:, 'year'] = year\n",
    "\n",
    "# Empy dictionary to actualizate variables labels of meta data\n",
    "    var_labels = {}\n",
    "    var_labels.update(meta_1.column_names_to_labels)\n",
    "    var_labels.update(meta_2.column_names_to_labels)\n",
    "    var_labels.update(meta_3.column_names_to_labels)\n",
    "\n",
    "# Empty dictionary to actualizate value labels of meta data    \n",
    "    value_labels = {}\n",
    "    value_labels.update(meta_1.variable_value_labels)\n",
    "    value_labels.update(meta_2.variable_value_labels)\n",
    "    value_labels.update(meta_3.variable_value_labels)\n",
    "\n",
    "# Merging data\n",
    "    endes_data = rec1_1.merge(rec2_1, on='CASEID', how='outer')\n",
    "    endes_data = endes_data.merge(rec3_1, on='CASEID', how='outer')\n",
    "    \n",
    "    all_data[f'year_{year}'] = {'data': endes_data, 'var_labels': var_labels, 'value_labels': value_labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating empty list for df's\n",
    "data_sets = []\n",
    "\n",
    "# Loop to take df's of all years and saved in data_sets list\n",
    "for year_key, year_data in all_data.items():\n",
    "    data_sets.append(year_data['data'])\n",
    "\n",
    "# All data frames are concated in a data frame names endes_data_2015_2019\n",
    "endes_data_2015_2019 = pd.concat(data_sets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty dictionaries for value and variable labels\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "\n",
    "# Collect and organize variable and values by year and adds as new column\n",
    "for year_key, year_data in all_data.items():\n",
    "    year = int(year_key.split('_')[1])\n",
    "\n",
    "# Take variable labels for each year    \n",
    "    var_labels = year_data['var_labels']\n",
    "    \n",
    "# Take value lables for each year\n",
    "    value_labels = year_data['value_labels']\n",
    "\n",
    "# Store all variable labels\n",
    "    all_var_labels[year] = var_labels\n",
    "    \n",
    "# Store all value labels\n",
    "    all_value_labels[year] = value_labels\n",
    "    \n",
    "# Adding a new column\n",
    "endes_data_2015_2019['var_labels'] = {}\n",
    "endes_data_2015_2019['value_labels'] = {}\n",
    "\n",
    "for year in range(2015, 2020):#loop to check if var and value labels exist in the dictionaries and adds in new column\n",
    "    if year in all_var_labels:\n",
    "        endes_data_2015_2019[f'var_labels_year_{year}'] = all_var_labels[year]\n",
    "    if year in all_value_labels:\n",
    "        endes_data_2015_2019[f'value_labels_year_{year}'] = all_value_labels[year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for departaments and keys\n",
    "departments = {\n",
    "    1: 'Amazonas',\n",
    "    2: 'Ancash',\n",
    "    3: 'Apurimac',\n",
    "    4: 'Arequipa',\n",
    "    5: 'Ayacucho',\n",
    "    6: 'Cajamarca',\n",
    "    7: 'Callao',\n",
    "    8: 'Cusco',\n",
    "    9: 'Huancavelica',\n",
    "    10: 'Huanuco',\n",
    "    11: 'Ica',\n",
    "    12: 'Junin',\n",
    "    13: 'La Libertad',\n",
    "    14: 'Lambayeque',\n",
    "    15: 'Lima',\n",
    "    16: 'Loreto',\n",
    "    17: 'Madre de Dios',\n",
    "    18: 'Moquegua',\n",
    "    19: 'Pasco',\n",
    "    20: 'Piura',\n",
    "    21: 'Puno',\n",
    "    22: 'San Martin',\n",
    "    23: 'Tacna',\n",
    "    24: 'Tumbes',\n",
    "    25: 'Ucayali'\n",
    "}\n",
    "\n",
    "endes_data_2015_2019['V024'] = endes_data_2015_2019['V024'].map(departments)\n",
    "\n",
    "# Grouping by year and computing means\n",
    "mean_key_vars = endes_data_2015_2019.groupby(['year', 'V024']).agg({\n",
    "    'V201': 'mean',\n",
    "    'V613': 'mean',\n",
    "    'V715': 'mean',\n",
    "    'V511': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns\n",
    "mean_key_vars = mean_key_vars.rename(columns={\n",
    "    'V201': 'mean_total_children',\n",
    "    'V613': 'mean_ideal_children',\n",
    "    'V715': 'mean_hb_yr_educ',\n",
    "    'V511': 'mean_first_marriage',\n",
    "    'V024': 'department'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data as final_result\n",
    "final_result = pd.merge(\n",
    "    endes_data_2015_2019,\n",
    "    mean_key_vars,\n",
    "    left_on=['year', 'V024'],\n",
    "    right_on=['year', 'department'],\n",
    "    how='left'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
