{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From number 1 to 5, we build upon the work done in assignment 3. _RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyreadstat\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "rec_1 = pd.read_spss(r\"../../_data/endes/2019/REC0111.sav\")\n",
    "rec_2 = pd.read_spss(r\"../../_data/endes/2019/RE223132.sav\")\n",
    "rec_3 = pd.read_spss(r\"../../_data/endes/2019/RE516171.sav\")\n",
    "\n",
    "import pyreadstat\n",
    "\n",
    "file_paths = [\n",
    "    \"../../_data/endes/2019/REC0111.sav\",\n",
    "    \"../../_data/endes/2019/RE223132.sav\",\n",
    "    \"../../_data/endes/2019/RE516171.sav\"\n",
    "]\n",
    "\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)\n",
    "\n",
    "    # Extract variable labels\n",
    "    if isinstance(meta.column_labels, list):\n",
    "        var_labels[file_path] = {col: label for col, label in zip(df.columns, meta.column_labels)}\n",
    "    else:\n",
    "        var_labels[file_path] = meta.column_labels\n",
    "\n",
    "    # Extract value labels\n",
    "    value_labels[file_path] = meta.variable_value_labels\n",
    "\n",
    "# Access variable and value labels for each file\n",
    "var_labels1 = var_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "var_labels2 = var_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "var_labels3 = var_labels[\"../../_data/endes/2019/RE516171.sav\"]\n",
    "\n",
    "value_labels1 = value_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "value_labels2 = value_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "value_labels3 = value_labels[\"../../_data/endes/2019/RE516171.sav\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_rec = [\n",
    "    ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "    ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "    ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "]\n",
    "\n",
    "# Iterate through the selected columns and perform the operations\n",
    "rec_list = [rec_1, rec_2, rec_3]\n",
    "new_var_labels_list = [var_labels1, var_labels2, var_labels3]\n",
    "new_value_labels_list = [value_labels1, value_labels2, value_labels3]\n",
    "\n",
    "for i in range(3):\n",
    "    # Update rec_i with selected columns\n",
    "    rec_i = rec_list[i][selected_columns_rec[i]]  # Fix this line\n",
    "\n",
    "    # Update variable labels for rec_i\n",
    "    new_var_labels_i = {key: value for key, value in new_var_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "\n",
    "    # Update value labels for rec_i\n",
    "    new_value_labels_i = {key: value for key, value in new_value_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "    \n",
    "    if i == 0:\n",
    "        rec1_1 = rec_i\n",
    "        new_var_labels1 = new_var_labels_i\n",
    "        new_value_labels1 = new_value_labels_i\n",
    "    elif i == 1:\n",
    "        rec2_1 = rec_i\n",
    "        new_var_labels2 = new_var_labels_i\n",
    "        new_value_labels2 = new_value_labels_i\n",
    "    elif i == 2:\n",
    "        rec3_1 = rec_i\n",
    "        new_var_labels3 = new_var_labels_i\n",
    "        new_value_labels3 = new_value_labels_i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/g41z_k153vvbyk6y_3whxsjc0000gn/T/ipykernel_34503/1712006461.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rec1_1.loc[:, 'year'] = 2019\n"
     ]
    }
   ],
   "source": [
    "# Generate a new column 'year' with the value 2019 using loc\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Update var_labels1 dictionary using the update method\n",
    "new_var_labels1.update({'year': 'Year of the survey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rec1_1, rec2_1, and rec3_1 using CASEID\n",
    "endes_2019 = rec1_1.merge(rec2_1, on='CASEID').merge(rec3_1, on='CASEID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify new_var_labels and new_value_labels into var_labels and value_labels\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "# Update var_labels and value_labels with the dictionaries from each rec dataframe\n",
    "var_labels.update(new_var_labels1)\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "value_labels.update(new_value_labels1)\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# Generate new attributes for endes_2019\n",
    "endes_2019['var_labels'] = var_labels\n",
    "endes_2019['value_labels'] = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyreadstat\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the nested dictionary to store all data\n",
    "all_data = {}\n",
    "\n",
    "# Iterate through the years 2015 to 2019\n",
    "for year in range(2015, 2020):\n",
    "    file_paths = [\n",
    "        f\"../../_data/endes/{year}/REC0111.sav\",\n",
    "        f\"../../_data/endes/{year}/RE223132.sav\",\n",
    "        f\"../../_data/endes/{year}/RE516171.sav\"\n",
    "    ]\n",
    "\n",
    "    var_labels = {}\n",
    "    value_labels = {}\n",
    "    selected_columns_rec = [\n",
    "        ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "        ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "        ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "    ]\n",
    "\n",
    "    rec_list = []\n",
    "    new_var_labels_list = []\n",
    "    new_value_labels_list = []\n",
    "\n",
    "  # Iterate through the files for each year\n",
    "for file_path in file_paths:\n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)\n",
    "\n",
    "    # Extract variable labels\n",
    "    if isinstance(meta.column_labels, list):\n",
    "        var_labels[file_path] = {col: label for col, label in zip(df.columns, meta.column_labels)}\n",
    "    else:\n",
    "        var_labels[file_path] = meta.column_labels\n",
    "\n",
    "    # Extract value labels\n",
    "    value_labels[file_path] = meta.variable_value_labels\n",
    "\n",
    "    # Update rec_list, new_var_labels_list, and new_value_labels_list\n",
    "    rec_list.append(df)  # Change this line\n",
    "    new_var_labels_list.append({key: value for key, value in var_labels[file_path].items() if key in selected_columns_rec[file_paths.index(file_path)]})\n",
    "    new_value_labels_list.append({key: value for key, value in value_labels[file_path].items() if key in selected_columns_rec[file_paths.index(file_path)]})\n",
    "\n",
    "    # Iterate through the rec_list, new_var_labels_list, and new_value_labels_list to create rec_i, new_var_labels_i, and new_value_labels_i\n",
    "    for i in range(len(rec_list)):\n",
    "        rec_i = rec_list[i]\n",
    "        new_var_labels_i = new_var_labels_list[i]\n",
    "        new_value_labels_i = new_value_labels_list[i]\n",
    "\n",
    "        if i == 0:\n",
    "            rec1_1 = rec_i\n",
    "            new_var_labels1 = new_var_labels_i\n",
    "            new_value_labels1 = new_value_labels_i\n",
    "        elif i == 1:\n",
    "            rec2_1 = rec_i\n",
    "            new_var_labels2 = new_var_labels_i\n",
    "            new_value_labels2 = new_value_labels_i\n",
    "        elif i == 2:\n",
    "            rec3_1 = rec_i\n",
    "            new_var_labels3 = new_var_labels_i\n",
    "            new_value_labels3 = new_value_labels_i\n",
    "\n",
    "    # Generate a new column 'year' with the value of the current year using loc\n",
    "    rec1_1.loc[:, 'year'] = year\n",
    "\n",
    "    # Update var_labels for the current year dictionary using the update method\n",
    "    new_var_labels1.update({'year': 'Year of the survey'})\n",
    "\n",
    "    # Merge rec1_1, rec2_1, and rec3_1 using CASEID\n",
    "    endes_year = rec1_1.merge(rec2_1, on='CASEID').merge(rec3_1, on='CASEID')\n",
    "\n",
    "    # Unify new_var_labels and new_value_labels into var_labels and value_labels for the current year\n",
    "    var_labels_year = {}\n",
    "    value_labels_year = {}\n",
    "\n",
    "    # Update var_labels_year and value_labels_year with the dictionaries from each rec dataframe for the current year\n",
    "    var_labels_year.update(new_var_labels1)\n",
    "    var_labels_year.update(new_var_labels2)\n",
    "    var_labels_year.update(new_var_labels3)\n",
    "\n",
    "    value_labels_year.update(new_value_labels1)\n",
    "    value_labels_year.update(new_value_labels2)\n",
    "    value_labels_year.update(new_value_labels3)\n",
    "\n",
    "    # Store the data, var_labels, and value_labels for the current year in the nested dictionary\n",
    "    all_data[f'year_{year}'] = {'data': endes_year, 'var_labels': var_labels_year, 'value_labels': value_labels_year}\n",
    "\n",
    "# Now, all_data contains the data, variable labels, and value labels for each year from 2015 to 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store all data sets\n",
    "all_datasets = []\n",
    "\n",
    "# Iterate through each year in all_data\n",
    "for year_key in all_data.keys():\n",
    "    # Get the merged_data for the current year\n",
    "    merged_data = all_data[year_key].get('merged_data')\n",
    "\n",
    "    # Check if merged_data is not None\n",
    "    if merged_data is not None:\n",
    "        # Append the current merged_data to the list\n",
    "        all_datasets.append(merged_data)\n",
    "\n",
    "# Concatenate all data sets into a single DataFrame\n",
    "endes_data_2015_2019 = pd.concat(all_datasets, ignore_index=True)\n",
    "\n",
    "# Reset the index for a clean DataFrame\n",
    "endes_data_2015_2019.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we create 2 new dictionaries.\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "\n",
    "#Second, we use a for loop to iterate over the years from 2015 to 2019.\n",
    "\n",
    "#We are extracting the variable and value labels associated with each year from all_data. Then we store them in the all_value_labels dictionary with the year as the key.\n",
    "\n",
    "for year in range( 2015, 2020 ):\n",
    "    all_var_labels[year] = all_data[ f'year_{year}' ]['var_labels']\n",
    "    all_value_labels[year] = all_data[ f'year_{year}' ]['value_labels']\n",
    "\n",
    "all_var_labels\n",
    "all_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we set the attributes var_label and value_labels which are assigned the information of the dictionaries previously created.\n",
    "\n",
    "endes_data_2015_2019_ta.attrs[ 'var_labels' ] = all_var_labels\n",
    "endes_data_2015_2019_ta.attrs[ 'value_labels' ] = all_value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant variables\n",
    "selected_vars = ['V201', 'V613', 'V715', 'V511']\n",
    "\n",
    "# Convert selected columns to numeric\n",
    "endes_data_2015_2019[selected_vars] = endes_data_2015_2019[selected_vars].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Group by 'year' and 'V024' (department), and calculate the mean\n",
    "mean_key_vars = endes_data_2015_2019.groupby(['year', 'V024'])[selected_vars].mean().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "mean_key_vars = mean_key_vars.rename(columns={\n",
    "    'V201': 'mean_total_children',\n",
    "    'V613': 'mean_ideal_children',\n",
    "    'V715': 'mean_hb_yr_educ',\n",
    "    'V511': 'mean_first_marriage'\n",
    "})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(mean_key_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mean_key_vars with endes_data_2015_2019\n",
    "final_result = pd.merge(endes_data_2015_2019, mean_key_vars, on=['year', 'V024'], how='left')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(final_result)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
