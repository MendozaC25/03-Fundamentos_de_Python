{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyper\n",
      "  Downloading hyper-0.7.0-py2.py3-none-any.whl (269 kB)\n",
      "     ---------------------------------------- 0.0/269.8 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/269.8 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/269.8 kB 435.7 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 61.4/269.8 kB 544.7 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 61.4/269.8 kB 544.7 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 204.8/269.8 kB 888.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 269.8/269.8 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting h2<3.0,>=2.4 (from hyper)\n",
      "  Downloading h2-2.6.2-py2.py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "     ---------------------- ----------------- 41.0/71.9 kB ? eta -:--:--\n",
      "     ---------------------- ----------------- 41.0/71.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 71.9/71.9 kB 493.2 kB/s eta 0:00:00\n",
      "Collecting hyperframe<4.0,>=3.2 (from hyper)\n",
      "  Downloading hyperframe-3.2.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting hpack<4,>=2.2 (from h2<3.0,>=2.4->hyper)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Installing collected packages: hyperframe, hpack, h2, hyper\n",
      "Successfully installed h2-2.6.2 hpack-3.0.0 hyper-0.7.0 hyperframe-3.2.0\n"
     ]
    }
   ],
   "source": [
    "import collections.abc\n",
    "#hyper needs the four following aliases to be done manually.\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "#Now import hyper\n",
    "!pip install hyper\n",
    "import hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\anaconda\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\anaconda\\lib\\site-packages (from pyreadstat) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
      "Requirement already satisfied: savReaderWriter in c:\\anaconda\\lib\\site-packages (3.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat\n",
    "!pip install savReaderWriter\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import savReaderWriter as sav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>HHID</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>...</th>\n",
       "      <th>QD333_4</th>\n",
       "      <th>QD333_5</th>\n",
       "      <th>QD333_6</th>\n",
       "      <th>UBIGEO</th>\n",
       "      <th>V022</th>\n",
       "      <th>V005</th>\n",
       "      <th>V190</th>\n",
       "      <th>V191</th>\n",
       "      <th>mujeres12a49</th>\n",
       "      <th>NCONGLOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000100201</td>\n",
       "      <td>000100201  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.234450</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000100201</td>\n",
       "      <td>000100201  3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.234450</td>\n",
       "      <td>Mujeres de 12 a 14 de edad, nunca embarazadas</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000102801</td>\n",
       "      <td>000102801  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.295611</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000102801</td>\n",
       "      <td>000102801  6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.295611</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000104801</td>\n",
       "      <td>000104801  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Pobrer</td>\n",
       "      <td>-0.256431</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325406201</td>\n",
       "      <td>325406201  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El más pobre</td>\n",
       "      <td>-1.750187</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38331</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325406301</td>\n",
       "      <td>325406301  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El más pobre</td>\n",
       "      <td>-1.676861</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407001</td>\n",
       "      <td>325407001  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>459792.0</td>\n",
       "      <td>El más pobre</td>\n",
       "      <td>-1.585333</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407201</td>\n",
       "      <td>325407201  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>459792.0</td>\n",
       "      <td>El más pobre</td>\n",
       "      <td>-1.650159</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38334</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407401</td>\n",
       "      <td>325407401  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El más pobre</td>\n",
       "      <td>-1.644720</td>\n",
       "      <td>Mujeres de 15 a 49 años de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38335 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID1             HHID              CASEID    V001  V002  V003  \\\n",
       "0      2019.0        000100201        000100201  2     1.0   2.0   2.0   \n",
       "1      2019.0        000100201        000100201  3     1.0   2.0   3.0   \n",
       "2      2019.0        000102801        000102801  2     1.0  28.0   2.0   \n",
       "3      2019.0        000102801        000102801  6     1.0  28.0   6.0   \n",
       "4      2019.0        000104801        000104801  2     1.0  48.0   2.0   \n",
       "...       ...              ...                 ...     ...   ...   ...   \n",
       "38330  2019.0        325406201        325406201  2  3254.0  62.0   2.0   \n",
       "38331  2019.0        325406301        325406301  2  3254.0  63.0   2.0   \n",
       "38332  2019.0        325407001        325407001  2  3254.0  70.0   2.0   \n",
       "38333  2019.0        325407201        325407201  2  3254.0  72.0   2.0   \n",
       "38334  2019.0        325407401        325407401  2  3254.0  74.0   2.0   \n",
       "\n",
       "         V004    V007    V008  V009  ...  QD333_4  QD333_5  QD333_6  UBIGEO  \\\n",
       "0         1.0  2019.0  1434.0   4.0  ...       No       No       No  010101   \n",
       "1         1.0  2019.0  1434.0   1.0  ...       No       No       No  010101   \n",
       "2         1.0  2019.0  1434.0   6.0  ...       No       No       No  010101   \n",
       "3         1.0  2019.0  1434.0   3.0  ...       No       No       No  010101   \n",
       "4         1.0  2019.0  1434.0   5.0  ...       No       No       No  010101   \n",
       "...       ...     ...     ...   ...  ...      ...      ...      ...     ...   \n",
       "38330  3254.0  2019.0  1440.0  12.0  ...       No       No       No  250401   \n",
       "38331  3254.0  2019.0  1440.0   6.0  ...       No       No       No  250401   \n",
       "38332  3254.0  2019.0  1440.0   7.0  ...       No       No       No  250401   \n",
       "38333  3254.0  2019.0  1440.0  12.0  ...       No       No       No  250401   \n",
       "38334  3254.0  2019.0  1440.0  10.0  ...       No       No       No  250401   \n",
       "\n",
       "        V022      V005          V190      V191  \\\n",
       "0        3.0  154803.0          Rico  1.234450   \n",
       "1        3.0  154803.0          Rico  1.234450   \n",
       "2        3.0  154803.0          Rico  1.295611   \n",
       "3        3.0  154803.0          Rico  1.295611   \n",
       "4        3.0  154803.0        Pobrer -0.256431   \n",
       "...      ...       ...           ...       ...   \n",
       "38330  249.0  244995.0  El más pobre -1.750187   \n",
       "38331  249.0  244995.0  El más pobre -1.676861   \n",
       "38332  249.0  459792.0  El más pobre -1.585333   \n",
       "38333  249.0  459792.0  El más pobre -1.650159   \n",
       "38334  249.0  244995.0  El más pobre -1.644720   \n",
       "\n",
       "                                        mujeres12a49  NCONGLOME  \n",
       "0                    Mujeres de 15 a 49 años de edad     7065.0  \n",
       "1      Mujeres de 12 a 14 de edad, nunca embarazadas     7065.0  \n",
       "2                    Mujeres de 15 a 49 años de edad     7065.0  \n",
       "3                    Mujeres de 15 a 49 años de edad     7065.0  \n",
       "4                    Mujeres de 15 a 49 años de edad     7065.0  \n",
       "...                                              ...        ...  \n",
       "38330                Mujeres de 15 a 49 años de edad    15783.0  \n",
       "38331                Mujeres de 15 a 49 años de edad    15783.0  \n",
       "38332                Mujeres de 15 a 49 años de edad    15783.0  \n",
       "38333                Mujeres de 15 a 49 años de edad    15783.0  \n",
       "38334                Mujeres de 15 a 49 años de edad    15783.0  \n",
       "\n",
       "[38335 rows x 105 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_1 = pd.read_spss( r\"../../_data/endes/2019/REC0111.sav\" )\n",
    "rec_2 = pd.read_spss( r\"../../_data/endes/2019/RE223132.sav\" )\n",
    "rec_3 = pd.read_spss( r\"../../_data/endes/2019/RE516171.sav\" )\n",
    "rec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/REC0111.sav\", ioUtf8=True ) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels1 = metadata.valueLabels\n",
    "    var_labels1 = metadata.varLabels\n",
    "\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE223132.sav\", ioUtf8=True ) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels2 = metadata.valueLabels\n",
    "    var_labels2 = metadata.varLabels\n",
    "\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE516171.sav\", ioUtf8=True ) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels3 = metadata.valueLabels\n",
    "    var_labels3 = metadata.varLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_vars1 = \"CASEID, V000, V001, V002, V003, V004, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133\".split( ', ' )\n",
    "sel_vars2 = \"CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380\".split(', ')\n",
    "sel_vars3 = \"CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715\".split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1 = rec_1.loc[ :, sel_vars1 ]\n",
    "rec2_1 = rec_2.loc[ :, sel_vars2 ]\n",
    "rec3_1 = rec_3.loc[ :, sel_vars3 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value_labels1 = { new_key: value_labels1[ new_key ] for new_key in sel_vars1 if new_key in value_labels1.keys() }\n",
    "new_var_labels1 = { new_key: var_labels1[ new_key ] for new_key in sel_vars1 }\n",
    "new_value_labels2 = { new_key: value_labels2[ new_key ] for new_key in sel_vars2 if new_key in value_labels2.keys() }\n",
    "new_var_labels2 = { new_key: var_labels2[ new_key ] for new_key in sel_vars2 }\n",
    "new_value_labels3 = { new_key: value_labels3[ new_key ] for new_key in sel_vars3 if new_key in value_labels3.keys() }\n",
    "new_var_labels3 = { new_key: var_labels3[ new_key ] for new_key in sel_vars3 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1.loc[ :, \"year\" ] = np.array( [ 2019 ] * len( rec1_1 ) )\n",
    "new_var_labels1.update( { 'year': \"Year of the survey\" } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endes_20191 = rec1_1.merge( rec2_1, on = 'CASEID' ).merge( rec3_1, on = 'CASEID' )\n",
    "# endes_20192 = rec1_1.merge( rec2_1, on = 'CASEID', how = 'outer' ).merge( rec3_1, on = 'CASEID', how = 'outer' )\n",
    "# endes_2019.shape == endes_20192.shape <- # Output is True\n",
    "\n",
    "endes_2019 = rec1_1.merge( rec2_1, on = 'CASEID', how = 'outer' ).merge( rec3_1, on = 'CASEID', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = urllib.request.urlopen( r'https://www.dropbox.com/s/gwcssinb1j9zr6s/endes_2019_ta.pkl?dl=1' )\n",
    "endes_2019_ta = pickle.load( output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels = {}\n",
    "var_labels.update(new_var_labels1)\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "value_labels = {}\n",
    "value_labels.update(new_value_labels1)\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.attrs[ 'var_labels' ] = var_labels\n",
    "endes_2019.attrs[ 'value_labels' ] = value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set1 = set( endes_2019.attrs[ 'var_labels' ] )\n",
    "# set2 = set( endes_2019_ta.attrs[ 'var_labels' ] )\n",
    "# set1 ^ set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.attrs[ 'var_labels' ] == endes_2019_ta.attrs[ 'var_labels' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.attrs[ 'value_labels' ] == endes_2019_ta.attrs[ 'value_labels' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_vars1 = \"CASEID, V000, V001, V002, V003, V004, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133\".split( ', ' )\n",
    "years = [ '2015', '2016', '2017', '2018', '2019' ]\n",
    "all_data = {}\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    data_1 = pd.read_spss( f\"../../_data/endes/{year}/REC0111.sav\" )\n",
    "    data_2 = pd.read_spss( f\"../../_data/endes/{year}/RE223132.sav\" )\n",
    "    data_3 = pd.read_spss( f\"../../_data/endes/{year}/RE516171.sav\" )\n",
    "    \n",
    "    with sav.SavHeaderReader( f\"../../_data/endes/{year}/REC0111.sav\", ioUtf8=True ) as header:\n",
    "        metadata = header.all()\n",
    "        value_labels1 = metadata.valueLabels\n",
    "        var_labels1 = metadata.varLabels\n",
    "\n",
    "    with sav.SavHeaderReader( f\"../../_data/endes/{year}/RE223132.sav\", ioUtf8=True ) as header:\n",
    "        metadata = header.all()\n",
    "        value_labels2 = metadata.valueLabels\n",
    "        var_labels2 = metadata.varLabels\n",
    "\n",
    "    with sav.SavHeaderReader( f\"../../_data/endes/{year}/RE516171.sav\", ioUtf8=True ) as header:\n",
    "        metadata = header.all()\n",
    "        value_labels3 = metadata.valueLabels\n",
    "        var_labels3 = metadata.varLabels\n",
    "    \n",
    "    data1_1 = data_1.loc[ :, sel_vars1 ]\n",
    "    data2_1 = data_2.loc[ :, sel_vars2 ]\n",
    "    data3_1 = data_3.loc[ :, sel_vars3 ]\n",
    "    \n",
    "    new_value_labels1 = { new_key: value_labels1[ new_key ] for new_key in sel_vars1 if new_key in value_labels1.keys() }\n",
    "    new_var_labels1 = { new_key: var_labels1[ new_key ] for new_key in sel_vars1 }\n",
    "    new_value_labels2 = { new_key: value_labels2[ new_key ] for new_key in sel_vars2 if new_key in value_labels2.keys() }\n",
    "    new_var_labels2 = { new_key: var_labels2[ new_key ] for new_key in sel_vars2 }\n",
    "    new_value_labels3 = { new_key: value_labels3[ new_key ] for new_key in sel_vars3 if new_key in value_labels3.keys() }\n",
    "    new_var_labels3 = { new_key: var_labels3[ new_key ] for new_key in sel_vars3 }\n",
    "    \n",
    "    data1_1.loc[ :, \"year\" ] = np.array( [ int( year ) ] * len( data1_1 ) )\n",
    "    new_var_labels1.update( { 'year': \"Year of the survey\" } )\n",
    "    \n",
    "    data = data1_1.merge( data2_1, on = 'CASEID' ).merge( data3_1, on = 'CASEID' )\n",
    "    \n",
    "    var_labels = {}\n",
    "    var_labels.update( new_var_labels1 )\n",
    "    var_labels.update( new_var_labels2 )\n",
    "    var_labels.update( new_var_labels3 )\n",
    "\n",
    "    value_labels = {}\n",
    "    value_labels.update( new_value_labels1 )\n",
    "    value_labels.update( new_value_labels2 )\n",
    "    value_labels.update( new_value_labels3 )\n",
    "    \n",
    "    all_data.update( { f'year_{ year }': { 'data': data, 'var_labels': var_labels, 'value_labels': value_labels } } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, we create a list that stores the entire data set\n",
    "all_datasets = []\n",
    "\n",
    "#Then we iterate every year.\n",
    "for year_key in all_data.keys():\n",
    "\n",
    "#We get the _merged data for the current year    \n",
    "    merged_data = all_data[year_key].get('merged_data')\n",
    "    \n",
    " #check if merged_data is none   \n",
    "     if merged_data is not None:\n",
    " #paste the merged data to the list       \n",
    "            all_datasets.append(merged_data)\n",
    " #put all the data together in a single dataframe   \n",
    "            endes_data_2015_2019 = pd.concat(all_datasets, ignore_index=True)\n",
    " #we reset the index for the dataframe   \n",
    "            endes_data_2015_2019.reset_index(drop=True, inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all we must create two dictionaries\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "\n",
    "#Then, a loop is used to iterate over the period of years\n",
    "#Now, we will extract the labels of the variables and their value in each year\n",
    "\n",
    "for year in range( 2015, 2020 ):\n",
    "    all_var_labels[year] = all_data[ f'year_{year}' ]['var_labels']\n",
    "    all_value_labels[year] = all_data[ f'year_{year}' ]['value_labels']\n",
    "\n",
    "all_var_labels\n",
    "all_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we establish the var_label and value_labels properties, to which the information from the previously defined dictionaries is assigned.\n",
    "endes_data_2015_2019_ta.attrs[ 'var_labels' ] = all_var_labels\n",
    "endes_data_2015_2019_ta.attrs[ 'value_labels' ] = all_value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
